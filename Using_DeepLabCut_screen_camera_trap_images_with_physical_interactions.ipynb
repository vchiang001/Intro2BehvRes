{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1XR845241n7aeFw7YIDJzrScTYdH4Sj3f",
      "authorship_tag": "ABX9TyOa8Dumqmwf4y4F0SLZsKQI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vchiang001/Intro2BehvRes/blob/main/Using_DeepLabCut_screen_camera_trap_images_with_physical_interactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using DeepLabCut to filter out MegaDetector analysed camera trap images that show physically interacting animals**\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1616492373700-PGOAC72IOB6AUE47VTJX/ke17ZwdGBToddI8pDm48kB8JrdUaZR-OSkKLqWQPp_YUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnBqyW03PFN2MN6T6ry5cmXqqA9xITfsbVGDrg_goIDasRCalqV8R3606BuxERAtDaQ/modelzoo.png?format=1000w)\n",
        "\n",
        "The understanding of sexual diversity including the sociosexual interactions between organisms requires consideration of the natural milieu of these behaviours , as well as the evolutionary perspectives by comparing across species. Camera trap data is pivotal for this purpose to look at these behaviours in wildlife animals, and to understand their context (e.g. where and when). For more details, you can refer to this presentation during the 2022 DeepLabCut AI Residency Program at EPFL: https://zenodo.org/record/7040375#.YyJ9a3bMK39 \n",
        "\n",
        "Our notebook runs on camera trap images that have been analysed using MegaDetector. More details on MegaDetector here: https://github.com/microsoft/CameraTraps/blob/main/megadetector.md \n",
        "\n",
        "Our notebook helps you isolate camera trap images that exhibit physical interactions. This is helpful because scientists invest a huge amount of time reviewing camera trap images, and a huge amount of that time is spent reviewing images they arenâ€™t interested in (e.g. empty images, noise). For those interested in sexual behaviour, this can filter out a substantial amount of images, to visually inspect those images with physical interaction, whether sexual behaviour could be occurring. \n",
        "\n",
        "For this work, we will use DeepLabCut from the model zoo. More details here: http://modelzoo.deeplabcut.org Please cite the relevant papers for the models you use, and consider giving back by helping to label more data. More details here: https://contrib.deeplabcut.org/ \n",
        "\n",
        "- **What you need:**camera trap images, and the JSON output file from MegaDetector analysis (ensure your camera trap images retain the same name in the JSON output file)\n",
        "\n",
        "- **What to do:** (1) in the top right corner, click \"CONNECT\". Then, just hit run (play icon) on each cell below and follow the instructions!\n"
      ],
      "metadata": {
        "id": "VgkZTHEws_xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's get going: install DeepLabCut into COLAB:**\n",
        "*Also, be sure you are connected to a GPU: go to menu, click Runtime > Change Runtime Type > select \"GPU\"*"
      ],
      "metadata": {
        "id": "ex64JvfLzfY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT4gL2Gzz_gX"
      },
      "outputs": [],
      "source": [
        "#click the play icon (this will take a few minutes to install all the dependences!)\n",
        "!pip install deeplabcut-live\n",
        "!pip install deeplabcut"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Be sure to click \"RESTART RUNTIME\" if it is displayed above before moving on !)**"
      ],
      "metadata": {
        "id": "ckkmk3vC1GhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's set the backend & import the DeepLabCut package:"
      ],
      "metadata": {
        "id": "Gc8Y3gWj3mVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# stifle tensorflow warnings, like we get it already.\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import deeplabcut"
      ],
      "metadata": {
        "id": "TNIMV3bW3lvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Link your Google Drive (containing camera trap images & JSON file):\n",
        "\n",
        "### First, place your camera trap image folder & JSON file into you google drive! "
      ],
      "metadata": {
        "id": "KzWAx4Xaz5En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VRJwtmcmz8ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "YOU WILL NEED TO EDIT THE FILE PATH & JSON PATH TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "Typically, this will be: /content/drive/My Drive/CameraTrapImages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup your project variables:\n",
        "# PLEASE EDIT THESE:\n",
        "file_path = '/content/drive/My Drive/CameraTrapImages'\n",
        "json_path = '/content/drive/My Drive/CameraTrapImages/megadetector.json'"
      ],
      "metadata": {
        "id": "lRluQKje1_dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select your model from the dropdown menu and set the model for analysis"
      ],
      "metadata": {
        "id": "9KF7WluQ2oYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
        "model_selection = widgets.Dropdown(\n",
        "    options=model_options,\n",
        "    value=model_options[0],\n",
        "    description=\"Choose a DLC ModelZoo model!\",\n",
        "    disabled=False\n",
        ")\n",
        "display(model_selection)"
      ],
      "metadata": {
        "id": "e8HNJyDI2yJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2use = model_selection.value\n",
        "from deeplabcut.utils import auxfun_models\n",
        "auxfun_models.download_model(modelname = model2use, target_dir = file_path)"
      ],
      "metadata": {
        "id": "nPQAil2o4Sez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOU WILL NEED TO EDIT THE MODEL PATH & POSE CONFIG PATH TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "This is currently set in your \"file_path\", so typically, this will be: /content/drive/My Drive/CameraTrapImages"
      ],
      "metadata": {
        "id": "R9chzoNb7Ktt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup where your model is\n",
        "# PLEASE EDIT THESE:\n",
        "model_path = '/content/drive/My Drive/CameraTrapImages'\n",
        "pose_cfg_path = model_path + '/pose_cfg.yaml' #copy the path to the pose_cfg.yaml "
      ],
      "metadata": {
        "id": "skIBu-tO6fF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This function crops the bounding box from the JSON output"
      ],
      "metadata": {
        "id": "IDD5MFCh7xES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image, ImageFile, ImageFont, ImageDraw\n",
        "import numpy as np\n",
        "from tensorflow.python.eager.context import global_seed\n",
        "def crop_detections(detect, img, imageWidth, imageHeight):\n",
        "    x1, y1,w_box, h_box = detect[\"bbox\"]\n",
        "    ymin,xmin,ymax, xmax = y1, x1, y1 + h_box, x1 + w_box \n",
        "    area = (xmin * imageWidth, \n",
        "            ymin * imageHeight, \n",
        "            xmax * imageWidth,\n",
        "            ymax * imageHeight)\n",
        "    cropping = img.crop(area)\n",
        "    list_np_crop = np.asarray(cropping)\n",
        "    return list_np_crop "
      ],
      "metadata": {
        "id": "o4sGQwMT7xim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This function runs the DeepLabCut model on individual MegaDetector bounding box"
      ],
      "metadata": {
        "id": "nt7qkVYV7-Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dlclive import DLCLive, Processor\n",
        "\n",
        "def predict_dlc(model_path, list_np_crop):\n",
        "    #list_np_crop = np.array(list_np_crop)\n",
        "    dlc_proc = Processor()\n",
        "    dlc_live = DLCLive(model_path, processor=dlc_proc)\n",
        "    dlc_live.init_inference(list_np_crop)\n",
        "    keypts_xyp = dlc_live.get_pose(list_np_crop) # third column is llk!\n",
        "    return keypts_xyp\n"
      ],
      "metadata": {
        "id": "MppIUjRS8Fpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This function converts the DeepLabCut poses normalised to the original image"
      ],
      "metadata": {
        "id": "u4LFkf9K8OGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from ruamel.yaml import YAML\n",
        "import pandas as pd \n",
        "def pose_orig_img(keypts_xyp, detect, pose_cfg_path):\n",
        "    x1, y1, w_box, h_box = detect[\"bbox\"] \n",
        "    keypts_xyp_orig_img = []\n",
        "    for x, y, p in keypts_xyp:\n",
        "        c = [x+x1, y+y1] \n",
        "        keypts_xyp_orig_img.append(c)\n",
        "    with open(pose_cfg_path, \"r\") as stream:\n",
        "        pose_cfg_dict = yaml.safe_load(stream)\n",
        "    bodypart_label = pose_cfg_dict['all_joints_names']\n",
        "    keypts_xyp_orig_img_df = pd.DataFrame (keypts_xyp_orig_img, columns = ['x', 'y'])\n",
        "    keypts_xyp_orig_img_df['bodypart'] = bodypart_label\n",
        "    keypts_xyp_orig_img_df = keypts_xyp_orig_img_df.set_index('bodypart')\n",
        "    return keypts_xyp_orig_img_df"
      ],
      "metadata": {
        "id": "McIpgCmP8Z23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This function obtains the reference length for each image (as each image differ in size) "
      ],
      "metadata": {
        "id": "gBvefqPu8fv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "from statistics import mean\n",
        "\n",
        "def nose2eye(allposes_names):\n",
        "  # get reference distance \n",
        "  eye_names = ['L_Eye', 'R_Eye', 'r_eye', 'l_eye', 'forehead', 'left_eye', 'right_eye']\n",
        "  nose_names = ['Nose', 'nose', 'chin'] \n",
        "  nose2eye_dist = [] \n",
        "  arbr_ref = float(4) #this is currently set as 4 arbitrarily if no nose and eyes are detected \n",
        "  nose2eye_dist.append(arbr_ref)    \n",
        "  for entity in allposes_names: \n",
        "      eye_list = [] \n",
        "      df_body = globals()[entity]\n",
        "      for body in df_body.index: \n",
        "          if body in eye_names: \n",
        "              eye_list.append(list(df_body.loc[body])) \n",
        "          if len(eye_list) != 0: \n",
        "              nose_list = [] \n",
        "              for body in df_body.index:\n",
        "                  if body in nose_names:\n",
        "                      nose_list.append(list(df_body.loc[body])) \n",
        "      for eye in eye_list: \n",
        "          dist = distance.euclidean(eye,nose_list)\n",
        "          nose2eye_dist.append(dist) \n",
        "  ref = min(nose2eye_dist)\n",
        "  return ref "
      ],
      "metadata": {
        "id": "0F9byD5m8miE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This function checks if there is physical interaction between individual MegaDetector boxes in each image"
      ],
      "metadata": {
        "id": "qFHgAVNT9DdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "def phys_int(allposes_names, ref):\n",
        "    int_matrx = [] \n",
        "    for entity in allposes_names: \n",
        "        df_body = globals()[entity]\n",
        "        xy = df_body.values.tolist() \n",
        "        for entity in allposes_names:\n",
        "            df_body2 = globals()[entity]\n",
        "            ab = df_body2.values.tolist() \n",
        "            for i in xy: \n",
        "                for b in ab: \n",
        "                    dist = distance.euclidean(i, b)\n",
        "                    if dist != 0: \n",
        "                        int_matrx.append(dist) \n",
        "    if any(i < ref for i in int_matrx): \n",
        "        social = \"physically interacting\"\n",
        "    else:\n",
        "      social = \"not physically interacting\"\n",
        "    return social "
      ],
      "metadata": {
        "id": "XJgD7B3t9Lzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After loading all the functions, we are ready to run! \n",
        "\n",
        "This creates a separate folder, and all camera trap images that exhibit physical interactions will be copied into the folder. \\\n",
        "Currently this is set to only the MegaDetector bounding boxes with confidence above 0.8, but this can be adjusted. "
      ],
      "metadata": {
        "id": "jXfQqX2s9Zri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open json file\n",
        "import json \n",
        "with open(json_path, 'r') as f:\n",
        "    detection_results = json.load(f)\n",
        "\n",
        "# this is used to temporary name bounding boxes\n",
        "import random \n",
        "import string  \n",
        "\n",
        "# creates a new folder to copy camera trap images with physical interactions\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "phys_int_path = os.path.join(file_path, \"phys_int_camtrap\")\n",
        "os.mkdir(phys_int_path) \n",
        "\n",
        "# this runs through all images in the JSON file\n",
        "for img_data in detection_results[\"images\"]:\n",
        "    img_path =  os.path.join(file_path, img_data['file'])\n",
        "    img = Image.open(img_path)\n",
        "    imageWidth = img.size[0]\n",
        "    imageHeight = img.size[1]\n",
        "    if len(img_data[\"detections\"]) >= 2: \n",
        "        allposes_names = [] \n",
        "        for detect in img_data[\"detections\"]: \n",
        "            if detect['conf'] > 0.8: \n",
        "                list_np_crop = crop_detections(detect, img, imageWidth, imageHeight)\n",
        "                keypts_xyp = predict_dlc(model_path, list_np_crop) \n",
        "                keypts_xyp_orig_img_df = pose_orig_img(keypts_xyp, detect, pose_cfg_path)\n",
        "                letters = string.ascii_letters \n",
        "                name =  ''.join(random.choice(letters) for i in range(10)) \n",
        "                allposes_names.append(name) \n",
        "                locals()[name] = keypts_xyp_orig_img_df\n",
        "        ref =  nose2eye(allposes_names)\n",
        "        social = phys_int(allposes_names, ref)\n",
        "        file = img_data['file'] \n",
        "        if social == \"physically interacting\":\n",
        "            shutil.copy(file_path+'/'+file, phys_int_path) "
      ],
      "metadata": {
        "id": "5uySVIDA9nne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Happy DeepLabCutting! Welcome to the Zoo :)"
      ],
      "metadata": {
        "id": "hDoXLVav-6Ts"
      }
    }
  ]
}